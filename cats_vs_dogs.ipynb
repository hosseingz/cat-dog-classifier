{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a convolutional neural network (CNN) to classify images of cats and dogs. The code is divided into the following sections:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Imports and Setup**\n",
    "\n",
    "* **`%pip install tensorflow-gpu`:** Installs the TensorFlow library with GPU support. \n",
    "* **Imports:** Includes necessary libraries for image processing, model building, and visualization.\n",
    "* **`BASE_DIR` and `DATA_DIR`:** Defines paths for the project root directory and the dataset location.\n",
    "* **`image_width`, `image_height`, `batch_size`:** Defines constants for image dimensions and training batch size.\n",
    "* **`print(tf.config.list_physical_devices('GPU'))`:** Prints available GPUs to ensure GPU acceleration is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from .preprocessing import Prc\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "BASE_DIR = '/content/'\n",
    "DATA_DIR = '/content/dataset/'\n",
    "\n",
    "image_width, image_height = 244, 244\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.Preprocessing**\n",
    "\n",
    "This section handles preprocessing of the dataset, including:\n",
    "\n",
    "- Downloading the dataset\n",
    "- Extracting the downloaded zip file\n",
    "- Verifying the downloaded images\n",
    "- Splitting the dataset into train and test sets\n",
    "\n",
    "The `Prc` class is used to perform these operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc = Prc()\n",
    "\n",
    "prc.download_dataset(\n",
    "    'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip',\n",
    "    'catsVsdogs.zip'\n",
    ")\n",
    "\n",
    "prc.extract_zip(\n",
    "    join(BASE_DIR, 'catsVsdogs.zip'),\n",
    "    BASE_DIR\n",
    ")\n",
    "\n",
    "prc.image_verification(\n",
    "    join(BASE_DIR, 'PetImages')\n",
    ")\n",
    "\n",
    "prc.split_dataset(\n",
    "    join(BASE_DIR, 'PetImages'),\n",
    "    DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Data Augmentation:**\n",
    "This section defines data augmentation techniques to increase the dataset size and prevent overfitting.\n",
    "  \n",
    "  - ImageDataGenerator is used to apply transformations like zoom, flip, rotation, width/height shifting, and shear.\n",
    "~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.4,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data_generator.flow_from_directory(join(BASE_DIR, 'Petimages', 'train'),\n",
    "        class_mode='binary', batch_size=batch_size, target_size=(image_width, image_height))\n",
    "\n",
    "test = test_data_generator.flow_from_directory(join(BASE_DIR, 'Petimages', 'test'),\n",
    "       class_mode='binary', batch_size=batch_size, target_size=(image_width, image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Model Definition:**\n",
    "\n",
    "This section defines the CNN model using the Sequential API. \n",
    "  - The model consists of convolutional layers, pooling layers, flattening layer, dense layers, and dropout layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Callbacks:**\n",
    "\n",
    "This section defines callbacks to enhance the training process:\n",
    "\n",
    "- EarlyStopping: Stops training when the validation loss stops improving for a certain number of epochs.\n",
    "- ReduceLROnPlateau: Reduces the learning rate when the validation loss plateaus.\n",
    "- ModelCheckpoint: Saves the best performing model based on the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, min_lr=0.001)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Model Training:**\n",
    "\n",
    "This section trains the model using the train and test data generators, specifies the number of epochs, and applies the defined callbacks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=100,\n",
    "    callbacks=[es, rlrop, checkpoint]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Plotting Training History:**\n",
    "This section plots the training and validation loss and accuracy over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LBT_OK'] = 'True'\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Saving the Model:**\n",
    "This section saves the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = join(BASE_DIR, 'models')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "model.save(\n",
    "    join(output_path, 'model.keras')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
